{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11db7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d66819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load('fashion_mnist', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8388e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(ds.as_numpy_iterator().next()[\"image\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiterator = ds.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a77360",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae2bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4):\n",
    "    batch = dataiterator.next()\n",
    "    ax[idx].imshow(np.squeeze(batch[\"image\"]))\n",
    "    ax[idx].title.set_text(batch[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9428c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale image\n",
    "def scale_images(data):\n",
    "    image = data[\"image\"]\n",
    "    return image/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e274f43",
   "metadata": {},
   "source": [
    "map\n",
    "cache\n",
    "shuffle\n",
    "batch\n",
    "prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044fc3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds= tfds.load(\"fashion_mnist\",split= \"train\")\n",
    "# running the dataset through the scale_image preprocessing step\n",
    "ds = ds.map(scale_images)\n",
    "# cache the dataset for the batch\n",
    "ds = ds.cache()\n",
    "# shuffle it up\n",
    "ds = ds.shuffle(60000)\n",
    "# batch into 128 images per sample\n",
    "ds= ds.batch(128)\n",
    "# reduces the likelihood of bottlenecking \n",
    "ds = ds.prefetch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.as_numpy_iterator().next().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1755b4",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2db02ad2",
   "metadata": {},
   "source": [
    " import modelling components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D , Dense , Flatten ,Reshape , LeakyReLU, Dropout , UpSampling2D"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7d0c2c5",
   "metadata": {},
   "source": [
    "Build Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model= Sequential()\n",
    "    \n",
    "    #block1 takes in random values and reshape it into 7x7x128\n",
    "    model.add(Dense(7*7*128 , input_dim = 128))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Reshape((7,7,128)))\n",
    "    \n",
    "    #upsampling block 1\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,5,padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    #upsampling block 2\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,5,padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # down sampling block 1\n",
    "    model.add(Conv2D(128,4,padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # down sampling block 2\n",
    "    model.add(Conv2D(128,4,padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    #Conv Layer to get to one Channel\n",
    "    model.add(Conv2D(1,4,padding=\"same\", activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=generator.predict(np.random.randn(4,128,1))\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0942032",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in   enumerate(img):\n",
    "    ax[idx].imshow(np.squeeze(img))\n",
    "    ax[idx].title.set_text(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da36d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD DISCRIMINATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1787a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "\n",
    "    #first conv Block\n",
    "    model.add(Conv2D(32,5,input_shape = (28,28,1)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    #second conv Block\n",
    "    model.add(Conv2D(64,5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # third conv Block\n",
    "    model.add(Conv2D(128,5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # fourth conv Block\n",
    "    model.add(Conv2D(256,5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    #flatten then pass to dense Layer\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator= build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc9997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.predict(np.expand_dims(img,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ba939",
   "metadata": {},
   "source": [
    "# Construct Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac799f",
   "metadata": {},
   "source": [
    "setup Losses and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3c5171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b689bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt= Adam(learning_rate=0.0001)\n",
    "d_opt = Adam(learning_rate=0.00001)\n",
    "g_loss= BinaryCrossentropy()\n",
    "d_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe7c854",
   "metadata": {},
   "source": [
    "Build Subclassed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the base model class to subclass our training steps\n",
    "from tensorflow.keras.models import Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e792a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionGAN(Model):\n",
    "    def __init__(self, generator,discriminator , *args,**kwargs):\n",
    "        # pass through args and kwards to base class\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        #create attributes for gen and disc\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "\n",
    "    def compile(self, g_opt,d_opt,g_loss,d_loss,*args, **kwargs):\n",
    "\n",
    "        super().compile(*args, **kwargs)\n",
    "        self.g_opt= g_opt\n",
    "        self.d_opt= d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss\n",
    "\n",
    "    def train_step(self, batch):\n",
    "\n",
    "        #get the real data\n",
    "        real_images = batch\n",
    "        fake_images = self.generator(tf.random.normal((128,128,1)), training=False)\n",
    "\n",
    "        #train the discriminator\n",
    "        with tf.GradientTape() as d_tape:\n",
    "\n",
    "            #pass the real and fake images to the discriminator model\n",
    "            yhat_real = self.discriminator(real_images, training= True)\n",
    "            yhat_fake= self.discriminator(fake_images, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real,yhat_fake],axis=0)\n",
    "\n",
    "            #create Labels for real and fake images\n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real),tf.ones_like(yhat_fake)], axis=0)\n",
    "\n",
    "            # Add some noise to the true outputs\n",
    "            noise_real= 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake= -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real,noise_fake],axis=0)\n",
    "\n",
    "\n",
    "            # Calculate loss\n",
    "\n",
    "            total_d_loss= self.d_loss(y_realfake,yhat_realfake)\n",
    "\n",
    "        # Apply backpropagation  -nn learn\n",
    "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables)\n",
    "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
    "\n",
    "        #train the generator\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            #generate some new images\n",
    "            gen_images = self.generator(tf.random.normal((128,128,1)), training= True)\n",
    "            #create the predicted labels\n",
    "            predected_labels = self.discriminator(gen_images,training= False)\n",
    "            #calculate loss -trick to training to fake out the discriminator\n",
    "            total_g_loss= self.g_loss(tf.zeros_like(predected_labels), predected_labels)\n",
    "        #apply backprop\n",
    "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "\n",
    "        return {\"d_loss\": total_d_loss , \"g_loss\":total_g_loss}\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of subclassed model\n",
    "\n",
    "fashgan = FashionGAN(generator , discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model \n",
    "fashgan.compile(g_opt,d_opt,g_loss,d_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d0ad4",
   "metadata": {},
   "source": [
    "Build Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0118af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98251643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=3 , latent_dim =128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.uniform((self.num_img,self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img= array_to_img(generated_images[i])\n",
    "            img.save(os.path.join('images', f\"generated_img_{epoch}_{i}.png\"))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = ModelMonitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e8ffb",
   "metadata": {},
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b974a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5346b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import platform\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(f\"SciPy {sp.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f2142",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Run on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    # Your model training code here\n",
    "    hist = fashgan.fit(ds, epochs=1, callbacks=[ModelMonitor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86386e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Loss')\n",
    "plt.plot(hist.history[\"d_loss\"],label=\"d_loss\")\n",
    "plt.plot(hist.history[\"g_loss\"],label=\"g_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c57aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = generator.predict(tf.random.normal((16,128,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a6542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(ncols=4,nrows=4, figsize=(10,10))\n",
    "for r in range(4):\n",
    "    for c in range(4):\n",
    "        ax[r][c].imshow(imgs[(r+1)*(c+1)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7570435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb90a71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
